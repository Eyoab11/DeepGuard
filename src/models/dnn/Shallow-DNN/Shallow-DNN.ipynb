{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d440da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report, roc_curve, auc)\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059471fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Keras imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Verify TensorFlow\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    print(\"Keras imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(\"Keras import error:\", e)\n",
    "    print(\"Please reinstall TensorFlow: pip uninstall tensorflow -y; pip install tensorflow==2.18.0\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c373cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154fe5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('../../../data/processed/train.csv')\n",
    "    val_df = pd.read_csv('../../../data/processed/val.csv')\n",
    "    test_df = pd.read_csv('../../../data/processed/test.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: Preprocessed data files not found. Ensure 'train.csv', 'val.csv', 'test.csv' exist.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96169dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data:\n",
      "Train shape: (2932930, 38), Validation shape: (628485, 38), Test shape: (628485, 38)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_train = train_df.drop('binary_label', axis=1)\n",
    "y_train = train_df['binary_label']\n",
    "X_val = val_df.drop('binary_label', axis=1)\n",
    "y_val = val_df['binary_label']\n",
    "X_test = test_df.drop('binary_label', axis=1)\n",
    "y_test = test_df['binary_label']\n",
    "\n",
    "print(\"Loaded preprocessed data:\")\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449de35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('shallow_dnn_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('shallow_dnn_roc_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_prob)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05fe199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Shallow DNN\n",
    "def create_shallow_dnn(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_dim, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f204a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22906/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0806 - val_accuracy: 0.9903 - val_loss: 0.0290\n",
      "Epoch 2/50\n",
      "\u001b[1m22913/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0346 - val_accuracy: 0.9916 - val_loss: 0.0243\n",
      "Epoch 3/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0303 - val_accuracy: 0.9919 - val_loss: 0.0228\n",
      "Epoch 4/50\n",
      "\u001b[1m22909/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0282 - val_accuracy: 0.9920 - val_loss: 0.0224\n",
      "Epoch 5/50\n",
      "\u001b[1m22909/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0262 - val_accuracy: 0.9935 - val_loss: 0.0181\n",
      "Epoch 6/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0239 - val_accuracy: 0.9934 - val_loss: 0.0192\n",
      "Epoch 7/50\n",
      "\u001b[1m22908/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0239 - val_accuracy: 0.9941 - val_loss: 0.0171\n",
      "Epoch 8/50\n",
      "\u001b[1m22908/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0228 - val_accuracy: 0.9941 - val_loss: 0.0160\n",
      "Epoch 9/50\n",
      "\u001b[1m22905/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0217 - val_accuracy: 0.9943 - val_loss: 0.0159\n",
      "Epoch 10/50\n",
      "\u001b[1m22908/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0211 - val_accuracy: 0.9945 - val_loss: 0.0155\n",
      "Epoch 11/50\n",
      "\u001b[1m22906/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0205 - val_accuracy: 0.9946 - val_loss: 0.0145\n",
      "Epoch 12/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0201 - val_accuracy: 0.9942 - val_loss: 0.0156\n",
      "Epoch 13/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0200 - val_accuracy: 0.9946 - val_loss: 0.0151\n",
      "Epoch 14/50\n",
      "\u001b[1m22907/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0196 - val_accuracy: 0.9947 - val_loss: 0.0139\n",
      "Epoch 15/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0192 - val_accuracy: 0.9945 - val_loss: 0.0151\n",
      "Epoch 16/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0189 - val_accuracy: 0.9945 - val_loss: 0.0158\n",
      "Epoch 17/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0197 - val_accuracy: 0.9946 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0189 - val_accuracy: 0.9942 - val_loss: 0.0168\n",
      "Epoch 19/50\n",
      "\u001b[1m22914/22914\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0187 - val_accuracy: 0.9948 - val_loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Shallow DNN\n",
    "input_dim = X_train.shape[1]\n",
    "shallow_dnn = create_shallow_dnn(input_dim)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('shallow_dnn_best.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = shallow_dnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0b0eac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shallow DNN model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "shallow_dnn.save('shallow_dnn_final.h5')\n",
    "print(\"Shallow DNN model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d51fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow DNN Evaluation:\n",
      "Accuracy: 0.9946410813305011\n",
      "Precision: 0.9925563738227726\n",
      "Recall: 0.9967572762393315\n",
      "F1-Score: 0.9946523894356112\n",
      "ROC-AUC: 0.9998410595955298\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    314243\n",
      "           1       0.99      1.00      0.99    314242\n",
      "\n",
      "    accuracy                           0.99    628485\n",
      "   macro avg       0.99      0.99      0.99    628485\n",
      "weighted avg       0.99      0.99      0.99    628485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "shallow_pred = (shallow_dnn.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
    "shallow_prob = shallow_dnn.predict(X_test, verbose=0).flatten()\n",
    "shallow_metrics = evaluate_model(y_test, shallow_pred, shallow_prob, \"Shallow DNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "266b2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Shallow DNN Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Shallow DNN Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('shallow_dnn_training_history.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50eb70a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shallow DNN Metrics:\n",
      "             Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
      "Model                                                         \n",
      "Shallow DNN  0.994641   0.992556  0.996757  0.994652  0.999841\n"
     ]
    }
   ],
   "source": [
    "# Save metrics\n",
    "metrics_df = pd.DataFrame([shallow_metrics]).set_index('Model')\n",
    "metrics_df.to_csv('shallow_dnn_metrics.csv')\n",
    "print(\"\\nShallow DNN Metrics:\")\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}